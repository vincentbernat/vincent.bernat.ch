---
title: "Int√©gration d'un service en Go avec systemd: activation par socket"
description: |
  En utilisant l'activation par socket de systemd, il est possible d'effectuer
  des d√©ploiements sans impact d'un service Go en quelques lignes de code.
uuid: 5463b0ca-6eb9-48e8-a36e-ed8a829fdb8d
tags:
  - golang
---

Dans un [article pr√©c√©dent][previous post], j'ai soulign√© certaines
fonctionnalit√©s utiles de *systemd* pour √©crire un service en Go,
notamment pour indiquer la *disponibilit√©* et prouver la
*vivacit√©*. Un autre point int√©ressant est l'**activation par
socket**[^traduction]¬†: *systemd* √©coute pour le compte de
l'application et, lors de la premi√®re requ√™te, d√©marre le service avec
une copie de la socket en √©coute. Lennart Poettering [d√©taille dans un
article][details it in a blog post]¬†:

> Si un service meurt, sa socket d'√©coute reste en place, sans perdre
> un seul message. Apr√®s un red√©marrage du service suite √† une panne,
> il peut continuer l√† o√π il s'est arr√™t√©. Si un service est mis √†
> niveau, nous pouvons red√©marrer le service tout en conservant ses
> sockets, assurant ainsi que le service est continuellement
> disponible. Aucune connexion n'est perdue pendant la mise √† niveau.

[^traduction]: La traduction de *socket* en fran√ßais n'est pas
    √©vidente. Quand le contexte est suffisamment clair, je m'amuse
    parfois √† dire ¬´¬†chaussette¬†¬ª üß¶ car "socket" est parfois √©crit
    `sock` dans les programmes. On pourrait le traduire par ¬´¬†prise
    r√©seau¬†¬ª, id√©al pour rendre perplexe la plupart des lecteurs.

Il s'agit d'une solution pour obtenir un **d√©ploiement sans impact**
d'une application. Un autre avantage est la possibilit√© d'ex√©cuter un
d√©mon avec moins de privil√®ges : perdre des droits est une t√¢che ardue
avec Go[^system].

[^system]: De nombreuses caract√©ristiques d'un processus sous Linux
    sont attach√©es aux fils d'ex√©cution. L'environnement d'ex√©cution
    de Go les g√®re de mani√®re transparente pour l'utilisateur. Jusqu'√†
    [r√©cemment][recently], cela rendait certaines fonctionnalit√©s,
    comme `setuid()` ou `setns()`, inutilisables.

[TOC]

# La base

Reprenons notre sympathique serveur de pages 404 :

    ::go
    package main
    
    import (
        "log"
        "net"
        "net/http"
    )
    
    func main() {
        listener, err := net.Listen("tcp", ":8081")
        if err != nil {
            log.Panicf("cannot listen: %s", err)
        }
        http.Serve(listener, nil)
    }

Voici la version utilisant l'activation par socket, √† l'aide de
[go-systemd][]¬†:

    ::go hl_lines="11 19"
    package main
    
    import (
        "log"
        "net/http"
    
        "github.com/coreos/go-systemd/activation"
    )
    
    func main() {
        listeners, err := activation.Listeners(true) // ‚ù∂
        if err != nil {
            log.Panicf("cannot retrieve listeners: %s", err)
        }
        if len(listeners) != 1 {
            log.Panicf("unexpected number of socket activation (%d != 1)",
                len(listeners))
        }
        http.Serve(listeners[0], nil) // ‚ù∑
    }

En ‚ù∂, nous r√©cup√©rons les sockets en √©coute fournies par *systemd*. En
‚ù∑, nous utilisons la premi√®re d'entre elles pour servir les requ√™tes
HTTP. Testons le r√©sultat avec `systemd-socket-activate` :

    ::console
    $ go build 404.go
    $ systemd-socket-activate -l 8000 ./404
    Listening on [::]:8000 as 3.

Dans un autre terminal, effectuons quelques requ√™tes¬†:

    ::console
    $ curl '[::1]':8000
    404 page not found
    $ curl '[::1]':8000
    404 page not found

Deux fichiers sont n√©cessaires pour compl√©ter l'int√©gration avec
*systemd* :

 - un fichier `.socket` d√©crivant la socket,
 - un fichier `.service` d√©crivant le service associ√©.

Voici le contenu du fichier `404.socket` :

    ::ini
    [Socket]
    ListenStream = 8000
    BindIPv6Only = both
    
    [Install]
    WantedBy = sockets.target

La page de manuel [`systemd.socket(5)`][systemd.socket] d√©crit les
options disponibles. `BindIPv6Only = both` est explicitement utilis√©
car sa valeur par d√©faut d√©pend de la distribution. Voici ensuite le
contenu du fichier `404.service` :

    ::ini
    [Unit]
    Description = 404 micro-service
    
    [Service]
    ExecStart = /usr/bin/404

*systemd* sait que les deux fichiers sont li√©s car ils partagent un
m√™me pr√©fixe. Placez les dans `/etc/systemd/system` et ex√©cutez
`systemctl daemon-reload` et `systemctl start 404.‚Äãsocket`. Votre
service est d√©sormais pr√™t √† accepter des connexions !

# Gestion des connexions existantes

Notre serveur de pages 404 a un d√©faut majeur : les connexions
existantes sont sauvagement tu√©es lorsque le d√©mon est arr√™t√© ou
red√©marr√©. Corrigeons cela !

## Attendre quelques secondes les connexions existantes

Nous pouvons inclure une courte p√©riode de tol√©rance pour terminer les
connexions en cours. √Ä l'issue de celles-ci, les connexions restantes
sont tu√©es :

    ::go hl_lines="15 22"
    // √Ä la r√©ception du signal, ferme en douceur le serveur et
    // attend 5 secondes la fin des connexions en cours.
    done := make(chan struct{})
    quit := make(chan os.Signal, 1)
    server := &http.Server{}
    signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
    
    go func() {
        <-quit
        log.Println("server is shutting down")
        ctx, cancel := context.WithTimeout(context.Background(),
            5*time.Second)
        defer cancel()
        server.SetKeepAlivesEnabled(false)
        if err := server.Shutdown(ctx); err != nil {
            log.Panicf("cannot gracefully shut down the server: %s", err)
        }
        close(done)
    }()

    // Accepte de nouvelles connexions.
    server.Serve(listeners[0])
    
    // Attend la fin des connexions en cours avant de sortir.
    <-done

√Ä la r√©ception du signal de terminaison, la goroutine reprend et
[planifie l'arr√™t du service][schedule a shutdown of the service] :

> `Shutdown()` ferme en douceur le serveur sans interrompre les
> connexions actives. `Shutdown()` fonctionne en fermant d'abord les
> sockets en √©coute puis en fermant toutes les connexions inactives et
> enfin en attendant ind√©finiment que les connexions retombent au
> repos et s'arr√™tent.

Durant le red√©marrage, les nouvelles connexions ne sont pas
accept√©es : elles restent dans la file d'attente associ√©e √† la
socket. La taille de celle-ci est limit√©e et peut √™tre configur√©e avec
la directive `Backlog`. Sa valeur par d√©faut est 128. Vous pouvez
conserver cette valeur m√™me si votre service s'attend √† recevoir de
nombreuses connexions par seconde. Lorsque cette valeur est d√©pass√©e,
les connexions entrantes sont ignor√©es. Le client r√©essaye
automatiquement de se connecter. Sous Linux, par d√©faut, un client
tente 5 fois (`tcp_syn_retries`) en 3 minutes environ. C'est un bon
moyen d'√©viter l'effet de troupeau qui se manifesterait au red√©marrage
si la taille de la file d'attente √©tait augment√©e √† une valeur plus
√©lev√©e.

## Attendre plus longtemps les connexions existantes

Si vous voulez attendre la fin des connexions existantes pendant une
longue p√©riode, vous avez besoin d'une approche alternative pour
√©viter d'ignorer les nouvelles connexions pendant plusieurs
minutes. Il y a une astuce tr√®s simple : **demander √† *systemd* de ne
tuer aucun processus**. Avec `KillMode = none`, seule la commande
d'arr√™t est ex√©cut√©e et tous les processus existants ne sont pas
perturb√©s :

    ::ini hl_lines="6 7"
    [Unit]
    Description = slow 404 micro-service
    
    [Service]
    ExecStart = /usr/bin/404
    ExecStop  = /bin/kill $MAINPID
    KillMode  = none

Si vous red√©marrez le service, le processus en cours prend le temps
n√©cessaire pour s'arr√™ter et *systemd* lance imm√©diatement une
nouvelle instance, pr√™te √† r√©pondre aux requ√™tes avec sa propre copie
de la socket d'√©coute. Toutefois, nous perdons la capacit√© d'attendre
que le service s'arr√™te compl√®tement, soit par lui-m√™me, soit de force
apr√®s un temps limite avec `SIGKILL`.

## Attendre plus longtemps les connexions existantes (alternative)

Une alternative √† la solution pr√©c√©dente consiste √† **faire croire √†
*systemd* que le service est mort**Ô∏è pendant le red√©marrage.

    ::go hl_lines="26 27"
    done := make(chan struct{})
    quit := make(chan os.Signal, 1)
    server := &http.Server{}
    signal.Notify(quit,
        // red√©marrage:
        syscall.SIGHUP,
        // arr√™t:
        syscall.SIGINT, syscall.SIGTERM)
    go func() {
        sig := <-quit
        switch sig {
        case syscall.SIGINT, syscall.SIGTERM:
            // Arr√™t avec limite de temps.
            log.Println("server is shutting down")
            ctx, cancel := context.WithTimeout(context.Background(),
                15*time.Second)
            defer cancel()
            server.SetKeepAlivesEnabled(false)
            if err := server.Shutdown(ctx); err != nil {
                log.Panicf("cannot gracefully shut down the server: %s", err)
            }
        case syscall.SIGHUP: // ‚ù∂
            // Ex√©cute un processus √©ph√©m√®re et demande √† systemd de
            // le suivre au lieu de nous.
            log.Println("server is reloading")
            pid := detachedSleep()
            daemon.SdNotify(false, fmt.Sprintf("MAINPID=%d", pid))
            time.Sleep(time.Second)

            // Attend sans limite de temps la fin des connexions en cours.
            server.SetKeepAlivesEnabled(false)
            if err := server.Shutdown(context.Background()); err != nil {
                log.Panicf("cannot gracefully shut down the server: %s", err)
            }
        }
        close(done)
    }()

    // Sert lentement les requ√™tes.
    server.Handler = http.HandlerFunc(
        func(w http.ResponseWriter, r *http.Request) {
            time.Sleep(10 * time.Second)
            http.Error(w, "404 not found", http.StatusNotFound)
        })
    server.Serve(listeners[0])

    // Attend que toutes les connexions se terminent.
    <-done
    log.Println("server terminated")

La principale diff√©rence est le traitement du signal `SIGHUP` en ‚ù∂ :
un processus leurre de courte dur√©e est ex√©cut√© et *systemd* est
invit√© √† le suivre. Quand il meurt, *systemd* lancera une nouvelle
instance du service. Cette m√©thode n√©cessite quelques bricolages :
*systemd* a besoin que le leurre soit son fils mais Go [ne peut pas
facilement se mettre en arri√®re plan][cannot daemonize] seul. Par
cons√©quent, nous utilisons un court script Python inclu dans la
fonction `detachedSleep()`[^python]¬†:

    ::go
    // detachedSleep ex√©cute un processus dormant une seconde
    // en arri√®re plan et retourne son PID.
    func detachedSleep() uint64 {
        py := `
    import os
    import time
    
    pid = os.fork()
    if pid == 0:
        for fd in {0, 1, 2}:
            os.close(fd)
        time.sleep(1)
    else:
        print(pid)
    `
        cmd := exec.Command("/usr/bin/python3", "-c", py)
        out, err := cmd.Output()
        if err != nil {
            log.Panicf("cannot execute sleep command: %s", err)
        }
        pid, err := strconv.ParseUint(strings.TrimSpace(string(out)), 10, 64)
        if err != nil {
            log.Panicf("cannot parse PID of sleep command: %s", err)
        }
        return pid
    }

[^python]: Python est un bon candidat : il est sans doute disponible
    sur le syst√®me, il est d'assez bas niveau pour impl√©menter
    facilement la fonctionnalit√© et, en tant que langage interpr√©t√©,
    il ne n√©cessite pas d'√©tape de compilation.
    
    **MISE √Ä JOUR (03.2018):** Il n'y a pas besoin d'appeler `fork()`
    deux fois car il faut uniquement d√©tacher le leurre du processus
    courant. Cela simplifie sensiblement le code Python.

Pendant le rechargement, il peut y avoir une courte p√©riode pendant
laquelle le nouveau et l'ancien processus acceptent les requ√™tes
entrantes. Si vous ne le souhaitez pas, vous pouvez d√©placer la
cr√©ation du processus leurre en dehors de la goroutine, apr√®s
`server.Serve()` ou impl√©menter un m√©canisme de synchronisation. Il y
a aussi un √©ventuel probl√®me de concurrence lorsque nous disons √†
*systemd* de suivre un autre PID (voir [PR #7816][]).

Le fichier `404.service` doit √™tre mis √† jour :

    ::ini
    [Unit]
    Description = slow 404 micro-service
    
    [Service]
    ExecStart    = /usr/bin/404
    ExecReload   = /bin/kill -HUP $MAINPID
    Restart      = always
    NotifyAccess = main
    KillMode     = process

Chacune des directives suppl√©mentaires a son importance :

 - `ExecReload` indique comment recharger le processus (avec `SIGHUP`).
 - `Restart` indique de red√©marrer le processus s'il s'arr√™te de
   mani√®re ¬´ inattendue ¬ª, notamment lors du rechargement[^socket].
 - `NotifyAccess` pr√©cise quels sont les processus autoris√©s √† envoyer
   des notifications comme le changement de PID.
 - `KillMode` indique de ne tuer que le processus identifi√© comme
   principal. Les autres sont laiss√©s tranquilles.

[^socket]: Cette directive n'est pas essentielle car le processus
    serait aussi red√©marr√© via l'activation de la socket.

## D√©ploiement sans impact¬†?

Le d√©ploiement sans impact est une entreprise difficile sur Linux. Par
exemple, [HAProxy][] a eu une [longue][hack1] [liste][hack2] de
[tentatives][hack3] jusqu'√† ce qu'une [solution appropri√©e, mais
complexe][proper‚Äîand complex‚Äîsolution], soit impl√©ment√©e dans
*HAproxy* 1.8. Comment se d√©brouille-t-on avec notre simple mise en
≈ìuvre ?

Du point de vue du noyau, il y a **une seule socket** avec une **file
d'attente unique**. Cette socket est associ√©e √† plusieurs descripteurs
de fichiers : un dans *systemd* et un dans le processus en cours. La
chaussette reste en vie tant qu'il y a au moins un descripteur de
fichier. Une connexion entrante est plac√©e par le noyau dans la file
d'attente et peut √™tre trait√©e √† partir de n'importe quel descripteur
avec l'appel syst√®me `accept()`. Par cons√©quent, cette approche permet
de r√©aliser un d√©ploiement sans impact : aucune connexion entrante
n'est rejet√©e.

En revanche, *HAProxy* utilisait plusieurs sockets diff√©rentes pour
√©couter sur les m√™mes adresses, gr√¢ce √† l'option
[`SO_REUSEPORT`][SO_REUSEPORT][^why]. Chaque socket a sa propre file
d'attente et le noyau r√©partit les connexions entrantes entre chacune
d'elles. Lorsqu'une socket se ferme, le contenu de sa file d'attente
est perdu. Si une connexion entrante se trouvait ici, elle re√ßoit une
r√©initialisation. Une modification √©l√©gante pour Linux afin de
[signaler qu'une socket ne devrait plus recevoir de nouvelles
connexions][signal a socket should not receive new connections] a √©t√©
rejet√©e. *HAProxy* 1.8 recycle d√©sormais les sockets existantes vers
les nouveaux processus par le biais d'une socket Unix.

[^why]: Cette approche est plus pratique lors d'un rechargement car il
    n'y a pas √† d√©terminer quelles sockets r√©utiliser et lesquelles
    cr√©er √† partir de z√©ro. De plus, lorsque plusieurs processus ont
    besoin d'accepter des connexions, l'utilisation de plusieurs
    sockets est plus performante car les diff√©rents processus ne se
    disputeront pas sur un verrou partag√© pour accepter des
    connexions.

J'esp√®re que ce billet et le [pr√©c√©dent][previous post] montrent
combien *systemd* est un compagnon appr√©ciable pour un service en Go :
*disponibilit√©*, *vivacit√©* et *activation par socket* sont quelques
unes des fonctionnalit√©s utiles pour construire une application plus
fiable.

# Annexe: leurre √©crit en Go

**MISE √Ä JOUR (03.2018) :** Sur [/r/golang][], on m'a fait remarquer
que, dans la version o√π *systemd* suit un leurre, le script Python
peut √™tre remplac√© par une invocation de l'ex√©cutable principal qui se
base sur un changement d'environnement pour prendre le r√¥le du
leurre. Voici le code rempla√ßant la fonction `detachedSleep()`
function :

    ::go
    func init() {
        // Au plus t√¥t, v√©rifie si on doit jouer le r√¥le
        // du leurre.
        state := os.Getenv("__SLEEPY")
        os.Unsetenv("__SLEEPY")
        switch state {
        case "1":
            // Premi√®re √©tape, se r√©ex√©cuter
            execPath := self()
            child, err := os.StartProcess(
                execPath,
                []string{execPath},
                &os.ProcAttr{
                    Env: append(os.Environ(), "__SLEEPY=2"),
                })
            if err != nil {
                log.Panicf("cannot execute sleep command: %s", err)
            }
    
            // Publie le PID du fils et sort.
            fmt.Printf("%d", child.Pid)
            os.Exit(0)
        case "2":
            // Dort et sort.
            time.Sleep(time.Second)
            os.Exit(0)
        }
    }
    
    // self retourne le chemin absolu vers nous-m√™me. Cela repose sur
    // /proc/self/exe qui peut √™tre un lien symbolique vers un fichier
    // supprim√© (durant une mise √† jour par exemple).
    func self() string {
        execPath, err := os.Readlink("/proc/self/exe")
        if err != nil {
            log.Panicf("cannot get self path: %s", err)
        }
        execPath = strings.TrimSuffix(execPath, " (deleted)")
        return execpath
    }
    
    // detachedSleep d√©tache un processus qui dort une seconde et retourne
    // son PID.
    func detachedSleep() uint64 {
        cmd := exec.Command(self())
        cmd.Env = append(os.Environ(), "__SLEEPY=1")
        out, err := cmd.Output()
        if err != nil {
            log.Panicf("cannot execute sleep command: %s", err)
        }
        pid, err := strconv.ParseUint(strings.TrimSpace(string(out)), 10, 64)
        if err != nil {
            log.Panicf("cannot parse PID of sleep command: %s", err)
        }
        return pid
    }

# Annexe : nommage des sockets

Pour un service donn√©, *systemd* peut fournir plusieurs sockets. Pour
les diff√©rencier, il est possible de les nommer. Par exemple,
supposons que nous voulions aussi retourner des codes d'erreur 403
depuis le m√™me service mais sur un port diff√©rent. Nous ajoutons une
d√©finition de socket suppl√©mentaire, `403.socket`, li√©e √† la t√¢che
`404.service` :

    ::ini hl_lines="4"
    [Socket]
    ListenStream = 8001
    BindIPv6Only = both
    Service      = 404.service
    
    [Install]
    WantedBy=sockets.target

√Ä moins de le sp√©cifier explicitement avec la directive
`FileDescriptorName`, le nom de la socket est le nom de l'unit√© :
`403.socket`. *go-systemd* fournit la fonction `ListenersWithName()`
pour r√©cup√©rer une correspondance entre les noms et les sockets :

    ::go hl_lines="24"
    package main
    
    import (
        "log"
        "net/http"
        "sync"
    
        "github.com/coreos/go-systemd/activation"
    )
    
    func main() {
        var wg sync.WaitGroup

        // Associe un nom de socket √† une fonction de gestion.
        handlers := map[string]http.HandlerFunc{
            "404.socket": http.NotFound,
            "403.socket": func(w http.ResponseWriter, r *http.Request) {
                http.Error(w, "403 forbidden",
                    http.StatusForbidden)
            },
        }
    
        // R√©cup√®re les sockets en √©coute.
        listeners, err := activation.ListenersWithNames(true)
        if err != nil {
            log.Panicf("cannot retrieve listeners: %s", err)
        }
    
        // Pour chaque socket, invoque une goroutine en utilisant
        // la fonction de gestion ad√©quate.
        for name := range listeners {
            for idx := range listeners[name] {
                wg.Add(1)
                go func(name string, idx int) {
                    defer wg.Done()
                    http.Serve(
                        listeners[name][idx],
                        handlers[name])
                }(name, idx)
            }
        }
    
        // Attend que toutes les goroutines terminent.
        wg.Wait()
    }

Compilons le service et lan√ßons le via `systemd-socket-activate`:

    ::console
    $ go build 404.go
    $ systemd-socket-activate -l 8000 -l 8001 \
    >                         --fdname=404.socket:403.socket \
    >                         ./404
    Listening on [::]:8000 as 3.
    Listening on [::]:8001 as 4.

Dans une autre console, nous pouvons tester une requ√™te sur chacune
des deux adresses :

    ::console
    $ curl '[::1]':8000
    404 page not found
    $ curl '[::1]':8001
    403 forbidden

[previous post]: [[fr/blog/2017-systemd-golang.html]] "Int√©gration d'un service en Go avec systemd: disponibilit√© et vivacit√©"
[details it in a blog post]: http://0pointer.de/blog/projects/socket-activation.html "systemd for Developers I: socket activation"
[go-systemd]: https://github.com/coreos/go-systemd/ "Go bindings for systemd"
[systemd.socket]: https://manpages.debian.org/stretch/systemd/systemd.socket.5.en.html "systemd.socket(5) manual page"
[schedule a shutdown of the service]: https://godoc.org/net/http#Server.Shutdown "godoc: net/http Server Shutdown"
[endless]: https://github.com/fvbock/endless "Zero downtime restarts for go servers"
[yet]: https://github.com/coreos/go-systemd/pull/251 "activation: add two functions to provide listeners with names"
[HAProxy]: https://www.haproxy.org/ "HAProxy: The Reliable, High Performance TCP/HTTP Load Balancer"
[hack1]: https://engineeringblog.yelp.com/2015/04/true-zero-downtime-haproxy-reloads.html "True Zero Downtime HAProxy Reload"
[hack2]: https://medium.com/@Drew_Stokes/actual-zero-downtime-with-haproxy-18318578fde6 "Actual Zero-Downtime with HAProxy"
[hack3]: https://githubengineering.com/glb-part-2-haproxy-zero-downtime-zero-delay-reloads-with-multibinder/ "GLB part 2: HAProxy zero-downtime, zero-delay reloads with multibinder"
[proper‚Äîand complex‚Äîsolution]: https://www.haproxy.com/blog/truly-seamless-reloads-with-haproxy-no-more-hacks/ "Truly Seamless Reloads with HAProxy ‚Äì No More Hacks!"
[SO_REUSEPORT]: https://manpages.debian.org/stretch/manpages/socket.7.en.html "socket - Linux socket interface"
[signal a socket should not receive new connections]: https://www.mail-archive.com/netdev@vger.kernel.org/msg91809.html "Re: [PATCH 1/1] net: Add SO_REUSEPORT_LISTEN_OFF socket option as drain mode"
[dup2]: https://manpages.debian.org/stretch/manpages-fr-dev/dup2.2.fr.html "dup, dup2, dup3 - Dupliquer un descripteur de fichier"
[PR #7816]: https://github.com/systemd/systemd/pull/7816 "Make MAINPID= and PIDFile= handling more restrictive"
[cannot daemonize]: https://github.com/golang/go/issues/227 "runtime: support for daemonize"
[recently]: https://golang.org/doc/go1.10#runtime "Go 1.10 Release Notes: Runtime"
[/r/golang]: https://www.reddit.com/r/golang/comments/85sm59/integration_of_a_go_service_with_systemd_socket/ "/r/golang: Integration of a Go service with systemd: socket activation"

{# Local Variables:      #}
{# mode: markdown        #}
{# indent-tabs-mode: nil #}
{# End:                  #}
